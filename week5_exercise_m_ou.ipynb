{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a format string (using `str.format()` and `f'string'`) that will take the following four element tuple:\n",
    "\n",
    "`( 2, 123.4567, 10000, 12345.67)`\n",
    "\n",
    "and produce:\n",
    "    \n",
    "`'file_002 :   123.46, 1.00e+04, 1.23e+04'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a python function that output the following formatted string based on the input iterable:\n",
    "\n",
    "`'The n numbers are: i1, i2, i3, ...'`\n",
    "    \n",
    "where `n` is the number in the iterable and `i1, i2 ...` are the items inside the iterable. \n",
    "\n",
    "for example:\n",
    "\n",
    "`func([1, 2, 3])` will return `'The 3 numbers are: 1, 2, 3'`\n",
    "\n",
    "`func((6, 7, 8, 9))` will return `'The 4 numbers are: 6, 7, 8, 9'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a similar function as the last one but it inputs variable-length arguments instead\n",
    "\n",
    "`func(1, 2, 3)` will return `'The 3 numbers are: 1, 2, 3'`\n",
    "\n",
    "`func(6, 7, 8, 9)` will return `'The 4 numbers are: 6, 7, 8, 9'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a format string (f'string') that will take the following tuple and return the formatted string below:\n",
    "\n",
    "Tuple: `(4, 30, 2017, 2, 27)`\n",
    "\n",
    "Return: `'02 27 2017 04 30'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a format string (f'string') that will take the following input and return the formatted string below:\n",
    "\n",
    "Input: `['oranges', 1.3, 'lemons', 1.1]`\n",
    "    \n",
    "Return: `'The weight of an orange is 1.3 and the weight of a lemon is 1.1 and the total weight is 2.4'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a function that will format each item in an input iterable object into a customized width \n",
    "\n",
    "syntax: `func(iterable, width)`\n",
    "\n",
    "for example:\n",
    "    \n",
    "`func([1, 2, 3, 4, 5], 3)`  return `'  1  2  3  4  5'`\n",
    "\n",
    "`func([1, 2, 3, 4, 5], 2)`  return `' 1 2 3 4 5'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. The USGS Water Data service provides retrival of streamflow data at the USGS stream gages. The download url follows the pattern below. Write a Python program 1) generate the url for a given list of gage numbers; 2) read this url and download the data to csv file (do not use numpy or pandas); 3) based on the downloaded data calculate the monthly stasticstics including maximum, minimum and average of the streamflow data and save it to another csv file. The data need to be formatted to 2 decimal digits. 4) calculate the average annual runoff of each gage (expressed in acre-feet) \n",
    "\n",
    "\n",
    "url: https://waterdata.usgs.gov/nwis/dv?&cb_00060=on&format=rdb&site_no=06803495&referred_module=sw&period=&begin_date=2019-02-11&end_date=2020-02-11\n",
    "\n",
    "where `&site_no=06803495` define which gages are included in this data retrieval; for multiple gages, simply repeat it, e.g. `&site_no=06803495&site_no=06803486`;\n",
    "\n",
    "the datas are specified by `&period=&begin_date=2018-02-11&end_date=2020-02-11`\n",
    "\n",
    "You could test your program using the gages `['06803495', '06803486']` for the period between `2000-10-1` and `2019-9-30`\n",
    "\n",
    "Hint 1: using the str.format() method to construct the url.\n",
    "\n",
    "Hint 2: use the `urllib.request.urlopen()` to download the url:\n",
    "```python\n",
    "    import urllib.request.urlopen\n",
    "    f = urllib.request.urlopen(a_url)\n",
    "    lines = f.readlines()\n",
    "```\n",
    "\n",
    "Hint 3: skip the lines starts with `#` in the downloaded data.\n",
    "\n",
    "Hint 4: print some of the downloaded lines and identify the elements in each line.\n",
    "\n",
    "Hint 5: using the str.format() or f-string method to write `csv` file.\n",
    "\n",
    "Hint 6: the monthly stasticstics refer to the time series of monthly stasticstics.\n",
    "\n",
    "Hint 7: for the average annual runoff, you need to calculate the total runoff for each year and then calculate average of these annual runoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://waterdata.usgs.gov/nwis/dv?&cb_00060=on&format=rdb&site_no=06803495&site_no=06803486&referred_module=sw&period=&begin_date=2000-10-10&end_date=2020-02-11\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "def generate_url(gagelist, begin_date, end_date):\n",
    "    try:\n",
    "        bdate = datetime.date.fromisoformat(begin_date)\n",
    "        edate = datetime.date.fromisoformat(end_date)\n",
    "    except:\n",
    "        raise ValueError (\"The input formats for the begin_date and end_date must be YYYY-MM-DD\")\n",
    "        \n",
    "    if type(gagelist) is not list:\n",
    "        raise TypeError('The gagelist must be a list type.')\n",
    "    \n",
    "    if gagelist == []:\n",
    "        raise ValueError('The gagelist must not be an empty list.')\n",
    "        \n",
    "    gages = ('&site_no={}' * len(gagelist)).format(*gagelist)\n",
    "    period = f'&period=&begin_date={begin_date}&end_date={end_date}'\n",
    "    return f'https://waterdata.usgs.gov/nwis/dv?&cb_00060=on&format=rdb{gages}&referred_module=sw{period}'\n",
    "\n",
    "print(generate_url(['06803495', '06803486'], '2000-10-10', '2019-09-30'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_usgs_flowdata(url):\n",
    "    f = urllib.request.urlopen(url)\n",
    "    return f.readlines()\n",
    "\n",
    "lines = read_usgs_flowdata(generate_url(['06803495', '06803486'], '2000-10-10', '2019-09-30'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'# ---------------------------------- WARNING ----------------------------------------\\n'\n",
      "b'# Some of the data that you have obtained from this U.S. Geological Survey database\\n'\n",
      "b\"# may not have received Director's approval. Any such data values are qualified\\n\"\n",
      "b'# as provisional and are subject to revision. Provisional data are released on the\\n'\n",
      "b'# condition that neither the USGS nor the United States Government may be held liable\\n'\n",
      "b'# for any damages resulting from its use.\\n'\n",
      "b'#\\n'\n",
      "b'# Additional info: https://help.waterdata.usgs.gov/policies/provisional-data-statement\\n'\n",
      "b'#\\n'\n",
      "b'# File-format description:  https://help.waterdata.usgs.gov/faq/about-tab-delimited-output\\n'\n",
      "b'# Automated-retrieval info: https://help.waterdata.usgs.gov/faq/automated-retrievals\\n'\n",
      "b'#\\n'\n",
      "b'# Contact:   gs-w_support_nwisweb@usgs.gov\\n'\n",
      "b'# retrieved: 2020-02-12 13:04:24 EST       (sdww01)\\n'\n",
      "b'#\\n'\n",
      "b'# Data for the following 2 site(s) are contained in this file\\n'\n",
      "b'#    USGS 06803486 Oak Creek at Air Park Road at Lincoln, Nebr.\\n'\n",
      "b'#    USGS 06803495 Salt Creek at Fairgrounds at Lincoln, Nebr.\\n'\n",
      "b'# -----------------------------------------------------------------------------------\\n'\n",
      "b'#\\n'\n",
      "b'# Data provided for site 06803486\\n'\n",
      "b'#            TS   parameter     statistic     Description\\n'\n",
      "b'#         93535       00060     00003     Discharge, cubic feet per second (Mean)\\n'\n",
      "b'#\\n'\n",
      "b'# Data-value qualification codes included in this output:\\n'\n",
      "b'#     A  Approved for publication -- Processing and review completed.\\n'\n",
      "b'#     P  Provisional data subject to revision.\\n'\n",
      "b'#     e  Value has been estimated.\\n'\n",
      "b'# \\n'\n",
      "b'agency_cd\\tsite_no\\tdatetime\\t93535_00060_00003\\t93535_00060_00003_cd\\n'\n",
      "b'5s\\t15s\\t20d\\t14n\\t10s\\n'\n",
      "b'USGS\\t06803486\\t2000-10-10\\t10.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-11\\t10.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-12\\t11.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-13\\t12.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-14\\t13.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-15\\t11.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-16\\t11.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-17\\t11.0\\tA\\n'\n",
      "b'USGS\\t06803486\\t2000-10-18\\t11.0\\tA\\n'\n"
     ]
    }
   ],
   "source": [
    "for l in lines[:40]:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USGS', '06803486', '2000-10-18', '11.0', 'A']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[39].decode().rstrip().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agency_cd,site_no,datetime,93535_00060_00003,93535_00060_00003_cd\n",
      "USGS,06803486,2000-10-10,10.0,A\n",
      "USGS,06803486,2000-10-11,10.0,A\n",
      "USGS,06803486,2000-10-12,11.0,A\n",
      "USGS,06803486,2000-10-13,12.0,A\n",
      "USGS,06803486,2000-10-14,13.0,A\n",
      "USGS,06803486,2000-10-15,11.0,A\n",
      "USGS,06803486,2000-10-16,11.0,A\n",
      "USGS,06803486,2000-10-17,11.0,A\n",
      "USGS,06803486,2000-10-18,11.0,A\n",
      "USGS,06803486,2000-10-19,11.0,A\n",
      "USGS,06803486,2000-10-20,10.0,A\n",
      "USGS,06803486,2000-10-21,9.60,A\n",
      "USGS,06803486,2000-10-22,12.0,A\n",
      "USGS,06803486,2000-10-23,13.0,A\n",
      "USGS,06803486,2000-10-24,14.0,A\n",
      "USGS,06803486,2000-10-25,16.0,A\n",
      "USGS,06803486,2000-10-26,15.0,A\n",
      "USGS,06803486,2000-10-27,14.0,A\n",
      "USGS,06803486,2000-10-28,16.0,A\n"
     ]
    }
   ],
   "source": [
    "def save_date(data_lines, csvfile):\n",
    "    for n, l in enumerate(data_lines):\n",
    "        if not l.startswith(b'#'):\n",
    "            break\n",
    "    \n",
    "    # now start working on the lines containing data\n",
    "    with open(csvfile, 'w') as f:\n",
    "        # extract and write headers\n",
    "        f.write(data_lines[n].decode().replace('\\t', ','))\n",
    "        \n",
    "        # skip the column spec line\n",
    "        n += 2\n",
    "        for i, l in enumerate(data_lines[n:]):\n",
    "            if l.startswith(b'USGS'):\n",
    "                f.write(l.decode().replace('\\t', ','))\n",
    "                \n",
    "save_date(lines, 'usgs_streamflow.csv') \n",
    "\n",
    "! head -20 'usgs_streamflow.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agency_cd,site_no,datetime,93535_00060_00003,93535_00060_00003_cd\n",
      "USGS,06803486,2000-10-10,10.0,A\n",
      "USGS,06803486,2000-10-11,10.0,A\n",
      "USGS,06803486,2000-10-12,11.0,A\n",
      "USGS,06803486,2000-10-13,12.0,A\n",
      "USGS,06803486,2000-10-14,13.0,A\n",
      "USGS,06803486,2000-10-15,11.0,A\n",
      "USGS,06803486,2000-10-16,11.0,A\n",
      "USGS,06803486,2000-10-17,11.0,A\n",
      "USGS,06803486,2000-10-18,11.0,A\n",
      "USGS,06803486,2000-10-19,11.0,A\n",
      "USGS,06803486,2000-10-20,10.0,A\n",
      "USGS,06803486,2000-10-21,9.60,A\n",
      "USGS,06803486,2000-10-22,12.0,A\n",
      "USGS,06803486,2000-10-23,13.0,A\n",
      "USGS,06803486,2000-10-24,14.0,A\n",
      "USGS,06803486,2000-10-25,16.0,A\n",
      "USGS,06803486,2000-10-26,15.0,A\n",
      "USGS,06803486,2000-10-27,14.0,A\n",
      "USGS,06803486,2000-10-28,16.0,A\n",
      "USGS,06803495,2020-01-23,393,P\n",
      "USGS,06803495,2020-01-24,392,P\n",
      "USGS,06803495,2020-01-25,327,P\n",
      "USGS,06803495,2020-01-26,311,P\n",
      "USGS,06803495,2020-01-27,311,P\n",
      "USGS,06803495,2020-01-28,297,P\n",
      "USGS,06803495,2020-01-29,270,P\n",
      "USGS,06803495,2020-01-30,264,P\n",
      "USGS,06803495,2020-01-31,318,P\n",
      "USGS,06803495,2020-02-01,410,P\n",
      "USGS,06803495,2020-02-02,844,P\n",
      "USGS,06803495,2020-02-03,926,P\n",
      "USGS,06803495,2020-02-04,547,P\n",
      "USGS,06803495,2020-02-05,379,P\n",
      "USGS,06803495,2020-02-06,335,P\n",
      "USGS,06803495,2020-02-07,324,P\n",
      "USGS,06803495,2020-02-08,283,P\n",
      "USGS,06803495,2020-02-09,282,P\n",
      "USGS,06803495,2020-02-10,261,P\n",
      "USGS,06803495,2020-02-11,250,P\n"
     ]
    }
   ],
   "source": [
    "# write the file as binary\n",
    "def save_date(data_lines, csvfile):\n",
    "    for n, l in enumerate(data_lines):\n",
    "        if not l.startswith(b'#'):\n",
    "            break\n",
    "    \n",
    "    # now start working on the lines containing data\n",
    "    with open(csvfile, 'wb') as f:\n",
    "        # extract and write headers\n",
    "        f.write(data_lines[n].replace(b'\\t', b','))\n",
    "        \n",
    "        # skip the column spec line\n",
    "        n += 2\n",
    "        for i, l in enumerate(data_lines[n:]):\n",
    "            if l.startswith(b'USGS'):\n",
    "                f.write(l.replace(b'\\t', b','))\n",
    "                \n",
    "save_date(lines, 'usgs_streamflow.csv') \n",
    "\n",
    "! head -20 'usgs_streamflow.csv'\n",
    "! tail -20 'usgs_streamflow.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USGS', '06803486', '2018-11-22', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-11-23', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-11-24', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-11-25', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-11-30', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-12-01', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-12-02', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-12-03', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-12-04', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-12-27', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2018-12-28', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2019-01-06', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2019-01-07', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2019-01-08', 'Ice', 'P\\n']\n",
      "['USGS', '06803486', '2019-01-09', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2018-12-01', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2018-12-27', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-05', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-06', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-07', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-08', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-09', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-10', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-11', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-12', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-13', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-14', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-15', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-16', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-01-17', 'Ice', 'P\\n']\n",
      "['USGS', '06803495', '2019-02-04', 'Ice', 'P\\n']\n",
      "site_no,month,mean,min,max\n",
      "06803486,2000-10-01,12.80,9.60,17.00\n",
      "06803486,2000-11-01,13.90,11.00,19.00\n",
      "06803486,2000-12-01,11.61,10.00,14.00\n",
      "06803486,2001-01-01,22.94,10.00,46.00\n",
      "06803486,2001-02-01,59.75,22.00,370.00\n",
      "06803486,2001-03-01,45.06,23.00,147.00\n",
      "06803486,2001-04-01,29.90,24.00,37.00\n",
      "06803486,2001-05-01,83.03,25.00,441.00\n",
      "06803486,2001-06-01,124.60,45.00,978.00\n",
      "06803486,2001-07-01,24.06,14.00,42.00\n",
      "06803486,2001-08-01,12.09,7.70,18.00\n",
      "06803486,2001-09-01,13.82,8.10,40.00\n",
      "06803486,2001-10-01,44.16,9.63,76.30\n",
      "06803486,2001-11-01,66.59,61.00,83.10\n",
      "06803486,2001-12-01,47.43,5.86,93.70\n",
      "06803486,2002-01-01,15.64,7.56,20.60\n",
      "06803486,2002-02-01,15.51,5.23,26.00\n",
      "06803486,2002-03-01,16.98,9.04,29.40\n",
      "06803486,2002-04-01,15.80,13.50,24.60\n",
      "06803495,2018-07-01,208.35,77.10,1590.00\n",
      "06803495,2018-08-01,121.63,56.20,613.00\n",
      "06803495,2018-09-01,809.24,90.00,7190.00\n",
      "06803495,2018-10-01,215.82,83.70,890.00\n",
      "06803495,2018-11-01,116.64,99.30,152.00\n",
      "06803495,2018-12-01,456.07,158.00,2680.00\n",
      "06803495,2019-01-01,202.50,127.00,341.00\n",
      "06803495,2019-02-01,185.67,136.00,491.00\n",
      "06803495,2019-03-01,1574.26,137.00,12600.00\n",
      "06803495,2019-04-01,270.77,213.00,391.00\n",
      "06803495,2019-05-01,1305.55,191.00,8990.00\n",
      "06803495,2019-06-01,923.37,379.00,2780.00\n",
      "06803495,2019-07-01,286.90,145.00,1680.00\n",
      "06803495,2019-08-01,255.00,161.00,624.00\n",
      "06803495,2019-09-01,269.27,125.00,1250.00\n",
      "06803495,2019-10-01,446.55,125.00,3110.00\n",
      "06803495,2019-11-01,139.07,116.00,183.00\n",
      "06803495,2019-12-01,318.13,111.00,2810.00\n",
      "06803495,2020-01-01,273.77,159.00,488.00\n",
      "06803495,2020-02-01,440.09,250.00,926.00\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def mean(lst): \n",
    "    try:\n",
    "        while math.nan in lst:\n",
    "            lst.remove(math.nan)\n",
    "        return sum(lst) / len(lst) if len(lst) > 0 else 0\n",
    "    except:\n",
    "        print(lst)\n",
    "            \n",
    "def cal_month_stat(daily_csv, monthly_csv):\n",
    "    site = ''\n",
    "    date = ''\n",
    "    begin = True\n",
    "    with open(daily_csv) as f:\n",
    "        # skip the header\n",
    "        f.readline()\n",
    "        idx_site = 1\n",
    "        idx_date = 2\n",
    "        idx_val  = 3\n",
    "        for i, l in enumerate(f):\n",
    "            items = l.split(',')\n",
    "            \n",
    "            # if site or month change, update the key \n",
    "            if items[idx_site] != site or items[idx_date][:7] != date:\n",
    "                site = items[idx_site]\n",
    "                date = items[idx_date][:7]\n",
    "                key = f'{site},{date}'\n",
    "                if begin:\n",
    "                    site_month = {key: []}\n",
    "                    begin = False\n",
    "                else:\n",
    "                    site_month[key] = []\n",
    "                    \n",
    "            # append the data to the list        \n",
    "            if items[idx_val].replace('.', '0').isnumeric():\n",
    "                site_month[key].append(float(items[idx_val]))\n",
    "            else:\n",
    "                # some time it's frozen (ice)\n",
    "                print(items)\n",
    "    \n",
    "\n",
    "    # write the data\n",
    "    with open(monthly_csv, 'w') as fw:\n",
    "        # write the header first\n",
    "        fw.write('site_no,month,mean,min,max\\n')\n",
    "        for k in site_month:\n",
    "            if site_month[k] == []:\n",
    "                print(k, site_month[k]) \n",
    "            else:\n",
    "                fw.write(f'{k}-01,{mean(site_month[k]):.2f},{min(site_month[k]):.2f},{max(site_month[k]):.2f}\\n')\n",
    "            \n",
    "cal_month_stat('usgs_streamflow.csv', 'monthly_streamflow.csv')\n",
    "! head -20 'monthly_streamflow.csv'\n",
    "! tail -20 'monthly_streamflow.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no,year,runoff\n",
      "06803486,2000-01-01,2099.70\n",
      "06803486,2001-01-01,34437.36\n",
      "06803486,2002-01-01,13491.21\n",
      "06803486,2003-01-01,10859.17\n",
      "06803486,2004-01-01,8893.77\n",
      "06803486,2005-01-01,11422.25\n",
      "06803486,2006-01-01,12576.22\n",
      "06803486,2007-01-01,62805.82\n",
      "06803486,2008-01-01,95886.55\n",
      "06803486,2009-01-01,31100.03\n",
      "06803486,2010-01-01,71793.32\n",
      "06803486,2011-01-01,44719.34\n",
      "06803486,2012-01-01,16833.02\n",
      "06803486,2013-01-01,16039.26\n",
      "06803486,2014-01-01,70420.03\n",
      "06803486,2015-01-01,68874.45\n",
      "06803486,2016-01-01,79819.44\n",
      "06803486,2017-01-01,71579.50\n",
      "06803486,2018-01-01,47159.60\n",
      "06803486,2017-01-01,71579.50\n",
      "06803486,2018-01-01,47159.60\n",
      "06803486,2019-01-01,141541.49\n",
      "06803486,2020-01-01,10567.54\n",
      "06803495,2005-01-01,46383.27\n",
      "06803495,2006-01-01,44310.55\n",
      "06803495,2007-01-01,169856.53\n",
      "06803495,2008-01-01,252522.84\n",
      "06803495,2009-01-01,74851.44\n",
      "06803495,2010-01-01,214021.88\n",
      "06803495,2011-01-01,143072.33\n",
      "06803495,2012-01-01,66706.91\n",
      "06803495,2013-01-01,78682.31\n",
      "06803495,2014-01-01,147447.47\n",
      "06803495,2015-01-01,331812.30\n",
      "06803495,2016-01-01,202611.77\n",
      "06803495,2017-01-01,177919.34\n",
      "06803495,2018-01-01,162700.36\n",
      "06803495,2019-01-01,369937.19\n",
      "06803495,2020-01-01,26435.70\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "def cal_annual_runoff(daily_csv, annual_runoff_csv):\n",
    "    site = ''\n",
    "    year = ''\n",
    "    begin = True\n",
    "    with open(daily_csv) as f:\n",
    "        # skip the header\n",
    "        f.readline()\n",
    "        idx_site = 1\n",
    "        idx_date = 2\n",
    "        idx_val  = 3\n",
    "        for i, l in enumerate(f):\n",
    "            items = l.split(',')\n",
    "            \n",
    "            # if site or month change, update the key \n",
    "            if items[idx_site] != site or items[idx_date][:4] != year:\n",
    "                site = items[idx_site]\n",
    "                year = items[idx_date][:4]\n",
    "                key = f'{site},{year}'\n",
    "                if begin:\n",
    "                    site_year = {key: []}\n",
    "                    begin = False\n",
    "                else:\n",
    "                    site_year[key] = []\n",
    "                    \n",
    "            # append the data to the list        \n",
    "            if items[idx_val].replace('.', '0').isnumeric():\n",
    "                site_year[key].append(float(items[idx_val]) * 86400 / 43560)\n",
    "    \n",
    "\n",
    "    # write the data\n",
    "    with open(annual_runoff_csv, 'w') as fw:\n",
    "        # write the header first\n",
    "        fw.write('site_no,year,runoff\\n')\n",
    "        for k in site_year:\n",
    "            fw.write(f'{k}-01-01,{sum(site_year[k]):.2f}\\n')\n",
    "            \n",
    "cal_annual_runoff('usgs_streamflow.csv', 'annual_runoff.csv')\n",
    "! head -20 'annual_runoff.csv'\n",
    "! tail -20 'annual_runoff.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
